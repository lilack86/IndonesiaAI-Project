{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3520a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4500 validated image filenames belonging to 2 classes.\n",
      "Found 500 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 186s 1s/step - loss: 0.6900 - accuracy: 0.5733 - val_loss: 0.6696 - val_accuracy: 0.5940 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 184s 1s/step - loss: 0.6493 - accuracy: 0.6196 - val_loss: 0.6316 - val_accuracy: 0.6420 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 185s 1s/step - loss: 0.6377 - accuracy: 0.6458 - val_loss: 0.6220 - val_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 183s 1s/step - loss: 0.6099 - accuracy: 0.6702 - val_loss: 0.6041 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 183s 1s/step - loss: 0.5983 - accuracy: 0.6813 - val_loss: 0.5680 - val_accuracy: 0.6880 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 184s 1s/step - loss: 0.5756 - accuracy: 0.7064 - val_loss: 0.6041 - val_accuracy: 0.6520 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 184s 1s/step - loss: 0.5618 - accuracy: 0.7102 - val_loss: 0.5302 - val_accuracy: 0.7280 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 185s 1s/step - loss: 0.5515 - accuracy: 0.7118 - val_loss: 0.5185 - val_accuracy: 0.7660 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 188s 1s/step - loss: 0.5396 - accuracy: 0.7271 - val_loss: 0.5129 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 187s 1s/step - loss: 0.5301 - accuracy: 0.7327 - val_loss: 0.5003 - val_accuracy: 0.8020 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilakastara/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m RMSprop(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m optimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m SGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m     88\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SGD' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.legacy import Adam as LegacyAdam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load CSV file with image_id and Male columns\n",
    "celeba_data = pd.read_csv('clean_attribute_lila2.csv')\n",
    "celeba_data['male'] = celeba_data['male'].astype(str)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, valid_data = train_test_split(celeba_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Set up data generators\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory='Images',\n",
    "    x_col='file_name',\n",
    "    y_col='male',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=valid_data,\n",
    "    directory='Images',\n",
    "    x_col='file_name',\n",
    "    y_col='male',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "# Define hyperparameter values to be tuned\n",
    "depth_values = [18, 34, 50]\n",
    "kernel_size_values = [(3, 3), (5, 5)]\n",
    "dropout_rate_values = [0.2, 0.4, 0.6]\n",
    "l2_reg_values = [1e-4, 1e-3, 1e-2]\n",
    "learning_rate_values = [0.001, 0.01, 0.1]\n",
    "batch_size_values = [32, 64, 128]\n",
    "optimizer_values = ['adam', 'sgd', 'rmsprop']\n",
    "\n",
    "# Loop for hyperparameter tuning\n",
    "for depth in depth_values:\n",
    "    for kernel_size in kernel_size_values:\n",
    "        for dropout_rate in dropout_rate_values:\n",
    "            for l2_reg in l2_reg_values:\n",
    "                for learning_rate in learning_rate_values:\n",
    "                    for batch_size in batch_size_values:\n",
    "                        for optimizer in optimizer_values:\n",
    "                            # Load ResNet101 model without the top layer\n",
    "                            base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "                            # Freeze the layers of the pre-trained model\n",
    "                            for layer in base_model.layers:\n",
    "                                layer.trainable = False\n",
    "\n",
    "                            # Create a new model on top of ResNet101\n",
    "                            model = Sequential()\n",
    "                            model.add(base_model)\n",
    "                            model.add(GlobalAveragePooling2D())\n",
    "                            model.add(Dense(128, activation='relu'))\n",
    "                            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                            # Set up optimizer\n",
    "                            if optimizer == 'adam':\n",
    "                                optimizer = Adam(learning_rate=learning_rate)\n",
    "                            elif optimizer == 'rmsprop':\n",
    "                                optimizer = RMSprop(learning_rate=learning_rate)\n",
    "                            elif optimizer == 'sgd':\n",
    "                                optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "                            # Compile the model\n",
    "                            model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                            # Implement ReduceLROnPlateau and EarlyStopping callbacks\n",
    "                            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6, verbose=1)\n",
    "                            early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "                            # Train the model\n",
    "                            history = model.fit(\n",
    "                                train_generator,\n",
    "                                epochs=10,\n",
    "                                validation_data=valid_generator,\n",
    "                                callbacks=[reduce_lr, early_stop]\n",
    "                            )\n",
    "\n",
    "                            # Save the trained model to an h5 file\n",
    "                            model.save(f\"ResNet101_Tuned_Depth{depth}_Kernel{kernel_size}_Dropout{dropout_rate}_L2{str(l2_reg)}_LR{str(learning_rate)}_Batch{batch_size}_Opt{optimizer}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
